 {
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import random\n",
    "import copy\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from prettytable import PrettyTable\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "class annotation(dict):\n",
    "    '''\n",
    "    将多个.json标注文件合并为同一个。导入时注意原有标注需要遵守以下格式，以免发生预料之外的错误：\n",
    "        - 标注遵守COCO格式，包含一些额外的标签信息。\n",
    "        - 各个数据集的图片分别存放在对应的文件夹里，建议图片的命名采用\"数据集名称+uuid+.jpg\"，保证混合后没有重名现象。\n",
    "    使用方法：\n",
    "        1. a = annotation() 新建一个对象\n",
    "        2. 单独使用 a.addSubset() 添加子数据集\n",
    "        3. 完成添加后用 a.save() 保存合并的标注文件，用 a.mergeFiles() 合并图片。\n",
    "        4. 使用 a.addBatch() 批量添加。Batch存放在文本文件中，从 fileName 参数传入文件名。文本格式：\n",
    "            instances_knife_2.json, knife_2\n",
    "            instances_firearm_1.json, firearm_1\n",
    "            [PATH TO ANNOTATION FILE], [DIRECTORY OF IMAGES]\n",
    "    '''\n",
    "\n",
    "    def __init__(self, name=\"SentryDataSet\", version: str = \"2.0\", url: str = \"\", annotPath: str = \"\", imgPath: str = \"\"):\n",
    "        '''\n",
    "        Args:\n",
    "            - annotPath: 初始数据集标注文件的位置。\n",
    "            - imgPath: 存放初始数据集图片的文件夹位置。\n",
    "            - version: 本次合并后输出的数据集版本号。\n",
    "            - url: 本次合并后数据集的说明页面，建议填写Notion页面的链接。\n",
    "            所有参数均为可选，其中annotPath和imgPath两项建议不填，这样类的初始化是一个空数据集，之后再逐步添加。\n",
    "        '''\n",
    "        try:\n",
    "            with open(annotPath, \"r\") as f:\n",
    "                ALL = json.load(f)\n",
    "                self.images = ALL[\"images\"]\n",
    "                self.annotations = ALL[\"annotations\"]\n",
    "                self.categories = ALL[\"categories\"]\n",
    "                self.licenses = ALL[\"licenses\"]\n",
    "                self.info = ALL[\"info\"]\n",
    "        except:\n",
    "            if annotPath != \"\":\n",
    "                print(\"文件%s未找到。\" % annotPath)\n",
    "            print(\"使用默认配置创建新的总标注对象%s v%s。\" % (name, version))\n",
    "            self.images = []\n",
    "            self.annotations = []\n",
    "            self.categories = []\n",
    "            self.licenses = [{\"name\": \"\", \"id\": 0, \"url\": \"\"}]\n",
    "            self.info = {\n",
    "                \"description\": \"地面哨兵数据集v%s\" % version,\n",
    "                \"url\": url,\n",
    "                \"version\": version,\n",
    "                \"year\": int(time.strftime(\"%Y\", time.localtime())),\n",
    "                \"contributor\": \"上海交通大学\",\n",
    "                \"date_created\": time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "            }\n",
    "        self.dirList = [] if imgPath == \"\" else [imgPath]\n",
    "        self.imageId = len(self.images)\n",
    "        self.annotId = len(self.annotations)\n",
    "        self.categoryId = len(self.categories)\n",
    "        self.categoryDict = {x[\"name\"]: x[\"id\"] for x in self.categories}\n",
    "        self.version = version\n",
    "        self.name = name\n",
    "        self.table = PrettyTable([\"源文件\", \"图片数量\", \"标注数量\"])\n",
    "        self.attrTables = []\n",
    "        self.status = {\"merged\": True, \"subsetNum\": 0}\n",
    "        self.latestImgP = \"\"\n",
    "        self.latestAnnot = \"\"\n",
    "\n",
    "    def _incrImageId(self):\n",
    "        self.imageId += 1\n",
    "        return self.imageId\n",
    "\n",
    "    def _incrAnnotId(self):\n",
    "        self.annotId += 1\n",
    "        return self.annotId\n",
    "\n",
    "    def _incrCategoryId(self):\n",
    "        self.categoryId += 1\n",
    "        return self.categoryId\n",
    "\n",
    "    @staticmethod\n",
    "    def dist(this, that):\n",
    "        return math.sqrt((this[0]-that[0])**2 + (this[1]-that[1])**2)\n",
    "\n",
    "    @staticmethod\n",
    "    def interplSeg(segmentation, minDist=5):\n",
    "        lastPoint = segmentation[-1]\n",
    "        newSeg = []\n",
    "        for point in segmentation:\n",
    "            if annotation.dist(point, lastPoint) <= minDist:\n",
    "                continue\n",
    "            lastInserted = lastPoint\n",
    "            interplSeg = []\n",
    "            while annotation.dist(point, lastInserted) > minDist:\n",
    "                lastInserted = [\n",
    "                    lastInserted[0] + minDist / (annotation.dist(\n",
    "                        point, lastInserted)) * (point[0]-lastInserted[0]),\n",
    "                    lastInserted[1] + minDist /\n",
    "                    (annotation.dist(point, lastInserted)) *\n",
    "                    (point[1]-lastInserted[1])\n",
    "                ]\n",
    "                interplSeg.append(lastInserted)\n",
    "            newSet += interplSeg\n",
    "            # TODO: 还未测试效果\n",
    "        return newSeg\n",
    "\n",
    "    def addSubset(self, annotPath=\"instances_all.json\", imagePath=\"\"):\n",
    "        currAnnot = []\n",
    "        imageTranslation = {}\n",
    "        categoryTranslation = {}\n",
    "        translatedImages = []\n",
    "        translatedAnnots = []\n",
    "        imageCounter = 0\n",
    "        annotCounter = 0\n",
    "        self.latestAnnot = annotPath\n",
    "        self.latestImgP = imagePath\n",
    "        with open(annotPath, \"r\") as f:\n",
    "            currAnnot = json.load(f)\n",
    "        # TODO: 合并类别\n",
    "        if imagePath != \"\":\n",
    "            self.dirList.append(imagePath)\n",
    "        for category in currAnnot[\"categories\"]:\n",
    "            if (category[\"name\"] in self.categoryDict.keys()):\n",
    "                categoryTranslation[category[\"id\"]\n",
    "                                    ] = self.categoryDict[category[\"name\"]]\n",
    "                continue\n",
    "            newCategoryId = self._incrCategoryId()\n",
    "            self.categoryDict[category[\"name\"]] = newCategoryId\n",
    "            self.categories.append({\n",
    "                \"id\": newCategoryId,\n",
    "                \"name\": category[\"name\"],\n",
    "                \"supercategory\": category[\"supercategory\"]\n",
    "            })\n",
    "            categoryTranslation[category[\"id\"]] = newCategoryId\n",
    "        for image in currAnnot[\"images\"]:\n",
    "            newImageId = self._incrImageId()\n",
    "            imageTranslation[image[\"id\"]] = newImageId\n",
    "            image[\"id\"] = newImageId\n",
    "            translatedImages.append(image)\n",
    "            imageCounter += 1\n",
    "        for annotation in currAnnot[\"annotations\"]:\n",
    "            annotation[\"id\"] = self._incrAnnotId()\n",
    "            annotation[\"image_id\"] = imageTranslation[annotation[\"image_id\"]]\n",
    "            annotation[\"category_id\"] = categoryTranslation[annotation[\"category_id\"]]\n",
    "            translatedAnnots.append(annotation)\n",
    "            annotCounter += 1\n",
    "        self.images += translatedImages\n",
    "        self.annotations += translatedAnnots\n",
    "        self.table.add_row([annotPath, imageCounter, annotCounter])\n",
    "        self.status[\"merged\"] = True and (self.status[\"subsetNum\"] <= 1)\n",
    "\n",
    "    def save(self, fileName: str, replace: bool = False) -> bool:\n",
    "        if os.path.exists(fileName) and not replace:\n",
    "            fileName = fileName.replace(\".json\", \"-1.json\")\n",
    "            print(\"标注文件已存在，改为导出到%s。\" % fileName)\n",
    "        data = {\n",
    "            \"licenses\": self.licenses,\n",
    "            \"info\": self.info,\n",
    "            \"categories\": self.categories,\n",
    "            \"images\": self.images,\n",
    "            \"annotations\": self.annotations\n",
    "        }\n",
    "        with open(fileName, \"w\") as f:\n",
    "            json.dump(data, f)\n",
    "            print(\"标注已导出到 %s。\" % (fileName))\n",
    "        print(\"统计：\")\n",
    "        self.table.add_row([\"总量\", self.imageId, self.annotId])\n",
    "        self.split(fileName=fileName.replace(\".json\", \"\"))\n",
    "        self.summary()\n",
    "        return True\n",
    "\n",
    "    def summary(self):\n",
    "        print(self.table)\n",
    "        for t in self.attrTables:\n",
    "            print(t)\n",
    "\n",
    "    def mergeFiles(self, replace: bool = False) -> bool:\n",
    "        if len(self.dirList) == 0:\n",
    "            return False\n",
    "        outPath = \"%sv%s\" % (self.name, self.version.replace(\".\", \"-\"))\n",
    "        if os.path.exists(outPath) and not replace:\n",
    "            print(\"目标路径 %s 已存在，中止拷贝过程。\" % outPath)\n",
    "            return False\n",
    "        elif os.path.exists(outPath) and replace:\n",
    "            print(\"目标路径 %s 已移除，开始拷贝。\" % outPath)\n",
    "            shutil.rmtree(outPath)\n",
    "        os.mkdir(outPath)\n",
    "        try:\n",
    "            for directory in self.dirList:\n",
    "                for image in os.listdir(directory):\n",
    "                    src = os.path.join(directory, image)\n",
    "                    dst = os.path.join(outPath, image)\n",
    "                    shutil.copyfile(src, dst)\n",
    "                    print(\"%s → %s\" % (src, dst))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return False\n",
    "        self.status[\"merged\"] = True\n",
    "        self.dirList = [outPath]\n",
    "        return True\n",
    "\n",
    "    def addBatch(self, fileName, inplace: bool = False) -> bool:\n",
    "        annotList = []\n",
    "        dirList = []\n",
    "        try:\n",
    "            with open(fileName, \"r\") as f:\n",
    "                allList = f.readlines()\n",
    "                annotList = [x.replace(\"\\n\", \"\").replace(\n",
    "                    \" \", \"\").split(\",\")[0] for x in allList]\n",
    "                dirList = []\n",
    "                try:\n",
    "                    dirList = [x.replace(\"\\n\", \"\").replace(\n",
    "                        \" \", \"\").split(\",\")[1] for x in allList]\n",
    "                except:\n",
    "                    pass  # 传入列表不包含图片路径\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return False\n",
    "        for i in range(len(annotList)):\n",
    "            self.addSubset(annotPath=annotList[i], imagePath=\"\" if len(\n",
    "                dirList) == 0 else dirList[i])\n",
    "        if inplace:\n",
    "            return self.save(fileName=\"%s_v%s.json\" % (self.name, self.version.replace(\".\", \"-\")), replace=True) and self.mergeFiles(replace=True)\n",
    "        return False\n",
    "\n",
    "    def split(self, fileName: str, train: int = 5, test: int = 1, val: int = 1):\n",
    "        print(\"按 train:test:val = %s:%s:%s 创建分割……\" % (train, test, val))\n",
    "        trainPercentage = train / (train + test + val)\n",
    "        testPercentage = test / (train + test + val)\n",
    "        trainLen = int(len(self.images) * trainPercentage)\n",
    "        testLen = int(len(self.images) * testPercentage)\n",
    "        allImageList = [x[\"file_name\"] for x in self.images]\n",
    "        self.trainList = list(random.sample(set(allImageList), trainLen))\n",
    "        self.testList = list(random.sample(\n",
    "            set(allImageList) - set(self.trainList), testLen))\n",
    "        self.valList = list(set(allImageList) -\n",
    "                            set(self.trainList) - set(self.testList))\n",
    "        table = PrettyTable([\"名称\", \"数量\"])\n",
    "        table.add_row([\"训练集 train\", trainLen])\n",
    "        table.add_row([\"测试集 test\", testLen])\n",
    "        table.add_row([\"验证集 val\", len(self.images) - trainLen - testLen])\n",
    "        print(table)\n",
    "        self.trainImages = []\n",
    "        self.testImages = []\n",
    "        self.valImages = []\n",
    "        self.trainAnnots = []\n",
    "        self.testAnnots = []\n",
    "        self.valAnnots = []\n",
    "        print(\"分割创建完成。正在保存标注文件……\")\n",
    "\n",
    "        image_id = 1\n",
    "        anno_id = 1\n",
    "        translation = {}\n",
    "        for image in self.images:\n",
    "            image_ = copy.deepcopy(image)\n",
    "            if (image_[\"file_name\"] in self.trainList):\n",
    "                translation[image_[\"id\"]] = image_id\n",
    "                image_[\"id\"] = image_id\n",
    "                self.trainImages.append(image_)\n",
    "                image_id += 1\n",
    "        for annotation in self.annotations:\n",
    "            annotation_ = copy.deepcopy(annotation)\n",
    "            if (self.images[annotation_[\"image_id\"]-1][\"file_name\"] in self.trainList):\n",
    "                annotation_[\"image_id\"] = translation[annotation[\"image_id\"]]\n",
    "                annotation_[\"id\"] = anno_id\n",
    "                self.trainAnnots.append(annotation_)\n",
    "                anno_id += 1\n",
    "        trainData = {\n",
    "            \"licenses\": self.licenses,\n",
    "            \"info\": self.info,\n",
    "            \"categories\": self.categories,\n",
    "            \"images\": self.trainImages,\n",
    "            \"annotations\": self.trainAnnots\n",
    "        }\n",
    "        with open(\"%s_train.json\" % fileName, \"w\") as f:\n",
    "            json.dump(trainData, f)\n",
    "            print(\"训练数据标注保存在 %s。\" % (\"%s_train.json\" % fileName))\n",
    "\n",
    "        image_id = 1\n",
    "        anno_id = 1\n",
    "        translation = {}\n",
    "        for image in self.images:\n",
    "            image_ = copy.deepcopy(image)\n",
    "            if (image_[\"file_name\"] in self.testList):\n",
    "                translation[image_[\"id\"]] = image_id\n",
    "                image_[\"id\"] = image_id\n",
    "                self.testImages.append(image_)\n",
    "                image_id += 1\n",
    "        for annotation in self.annotations:\n",
    "            annotation_ = copy.deepcopy(annotation)\n",
    "            if (self.images[annotation_[\"image_id\"]-1][\"file_name\"] in self.testList):\n",
    "                annotation_[\"image_id\"] = translation[annotation[\"image_id\"]]\n",
    "                annotation_[\"id\"] = anno_id\n",
    "                self.testAnnots.append(annotation_)\n",
    "                anno_id += 1\n",
    "        testData = {\n",
    "            \"licenses\": self.licenses,\n",
    "            \"info\": self.info,\n",
    "            \"categories\": self.categories,\n",
    "            \"images\": self.testImages,\n",
    "            \"annotations\": self.testAnnots\n",
    "        }\n",
    "        with open(\"%s_test.json\" % fileName, \"w\") as f:\n",
    "            json.dump(testData, f)\n",
    "            print(\"测试数据标注保存在 %s。\" % (\"%s_test.json\" % fileName))\n",
    "\n",
    "        image_id = 1\n",
    "        anno_id = 1\n",
    "        translation = {}\n",
    "        for image in self.images:\n",
    "            image_ = copy.deepcopy(image)\n",
    "            if (image_[\"file_name\"] in self.valList):\n",
    "                translation[image_[\"id\"]] = image_id\n",
    "                image_[\"id\"] = image_id\n",
    "                self.valImages.append(image_)\n",
    "                image_id += 1\n",
    "        for annotation in self.annotations:\n",
    "            annotation_ = copy.deepcopy(annotation)\n",
    "            if (self.images[annotation_[\"image_id\"]-1][\"file_name\"] in self.valList):\n",
    "                annotation_[\"image_id\"] = translation[annotation[\"image_id\"]]\n",
    "                annotation_[\"id\"] = anno_id\n",
    "                self.valAnnots.append(annotation_)\n",
    "                anno_id += 1\n",
    "        valData = {\n",
    "            \"licenses\": self.licenses,\n",
    "            \"info\": self.info,\n",
    "            \"categories\": self.categories,\n",
    "            \"images\": self.valImages,\n",
    "            \"annotations\": self.valAnnots\n",
    "        }\n",
    "        with open(\"%s_val.json\" % fileName, \"w\") as f:\n",
    "            json.dump(valData, f)\n",
    "            print(\"验证数据标注保存在 %s。\" % (\"%s_val.json\" % fileName))\n",
    "        print(\"正在保存分割文件……\")\n",
    "        with open(\"%s_train.txt\" % fileName, \"w\") as f:\n",
    "            f.writelines([x+\"\\n\" if x != self.trainList[-1]\n",
    "                          else x for x in self.trainList])\n",
    "            print(\"训练分割文件保存在 %s。\" % (\"%s_train.txt\" % fileName))\n",
    "        with open(\"%s_test.txt\" % fileName, \"w\") as f:\n",
    "            f.writelines([x+\"\\n\" if x != self.testList[-1]\n",
    "                          else x for x in self.testList])\n",
    "            print(\"测试分割文件保存在 %s。\" % (\"%s_test.txt\" % fileName))\n",
    "        with open(\"%s_val.txt\" % fileName, \"w\") as f:\n",
    "            f.writelines([x+\"\\n\" if x != self.valList[-1]\n",
    "                          else x for x in self.valList])\n",
    "            print(\"验证分割文件保存在 %s。\" % (\"%s_val.txt\" % fileName))\n",
    "\n",
    "    def checkAttributeIntegrity(self, tagSet={\"overlap\", \"hard\", \"visibility\", \"background_complex\", \"outdoor\", \"blur\", \"small_size\", \"over_crowded\"}\n",
    "                                ):\n",
    "        print(\"正在检查标注的标签是否完整……\")\n",
    "        stdAttributes = tagSet\n",
    "        wrongAttributeList = {}\n",
    "        annotId = 1\n",
    "        for annotation in self.annotations:\n",
    "            attributes = set(annotation[\"attributes\"].keys())\n",
    "            if attributes == stdAttributes:\n",
    "                continue\n",
    "            lostAttributes = stdAttributes - attributes\n",
    "            wrongAttributeList[annotId] = lostAttributes\n",
    "            for attribute in lostAttributes:\n",
    "                annotation[\"attributes\"][attribute] = \"N/A\"\n",
    "        if len(wrongAttributeList) != 0:\n",
    "            print('使用\"N/A\"填充了所有缺失标签。')\n",
    "        else:\n",
    "            print(\"检查完成，无标签缺失。\")\n",
    "        for k, v in wrongAttributeList:\n",
    "            print(\"编号%s的标注缺失标签：%s\" % (k, v))\n",
    "\n",
    "    def display(self, displayPath=\"display\"):\n",
    "        self.checkAttributeIntegrity()\n",
    "        OPT_PATH = displayPath\n",
    "        IMG_PATH = self.latestImgP\n",
    "        # 此函数的主代码从display.ipynb迁移而来\n",
    "        if not(self.status[\"merged\"]):\n",
    "            self.mergeFiles(replace=False)\n",
    "        ALL = {}\n",
    "        IMAGES = self.images\n",
    "        if os.path.exists(OPT_PATH):\n",
    "            shutil.rmtree(OPT_PATH)\n",
    "        os.mkdir(OPT_PATH)\n",
    "        IMAGES_PATH = {x[\"id\"]: x[\"file_name\"] for x in IMAGES}\n",
    "        for annotation in self.annotations:\n",
    "            imgPath1 = os.path.join(\n",
    "                IMG_PATH, IMAGES_PATH[annotation[\"image_id\"]])\n",
    "            imgPath2 = os.path.join(\n",
    "                OPT_PATH, IMAGES_PATH[annotation[\"image_id\"]])\n",
    "            imgPath = imgPath2 if os.path.exists(imgPath2) else imgPath1\n",
    "            img = cv2.imread(imgPath)\n",
    "            img = img.astype(np.int32)\n",
    "            b, g, r = cv2.split(img)\n",
    "            it = iter(annotation[\"segmentation\"][0])\n",
    "            seg = []\n",
    "            while True:\n",
    "                try:\n",
    "                    x = next(it)\n",
    "                    y = next(it)\n",
    "                    seg.append([x, y])\n",
    "                except StopIteration:\n",
    "                    break\n",
    "            seg_np = np.array([seg], dtype=np.int32)\n",
    "            im = np.zeros(img.shape[:2], dtype=np.int32)\n",
    "            cv2.polylines(im, seg_np, 1, 255)\n",
    "            cv2.fillPoly(im, seg_np, 255)\n",
    "            b_masked = cv2.addWeighted(b, 1, im, 0.5, 0)\n",
    "            g_masked = cv2.addWeighted(g, 1, im, 0.5, 0)\n",
    "            r_masked = cv2.addWeighted(r, 1, im, 0.5, 0)\n",
    "            img = cv2.merge([b_masked, g_masked, r_masked])\n",
    "            [x, y, w, h] = list(map(int, annotation[\"bbox\"]))\n",
    "            cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 3)\n",
    "            text = \"Category: %s\\n blur: %s\\n smallSize: %s\\n overCrowded: %s\\n overlap: %s\\n hard: %s\\n visibility: %s\\n bkg complex: %s\\n outdoor: %s\" % (\n",
    "                self.categories[annotation[\"category_id\"]-1][\"name\"],\n",
    "                annotation[\"attributes\"][\"blur\"],\n",
    "                annotation[\"attributes\"][\"small_size\"],\n",
    "                annotation[\"attributes\"][\"over_crowded\"],\n",
    "                annotation[\"attributes\"][\"overlap\"],\n",
    "                annotation[\"attributes\"][\"hard\"],\n",
    "                annotation[\"attributes\"][\"visibility\"],\n",
    "                annotation[\"attributes\"][\"background_complex\"],\n",
    "                annotation[\"attributes\"][\"outdoor\"]\n",
    "            )\n",
    "            lineHeight = 15\n",
    "            count = 0\n",
    "            for textSeg in text.split(\"\\n\"):\n",
    "                y_ = (y + count*lineHeight) if (y + count *\n",
    "                                                lineHeight) < b.shape[0] else b.shape[0]\n",
    "                cv2.putText(img, textSeg, (x, y_),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "                count += 1\n",
    "            cv2.imwrite(imgPath2, img)\n",
    "    #print(\"Annotation %s -> Image %s\" % (annotation[\"id\"], annotation[\"image_id\"]))\n",
    "\n",
    "    def generateAttributes(self):\n",
    "        self.generateBlurAttribute()\n",
    "        self.generateSizeAttribute()\n",
    "        self.generateOvercrowdedAttribute()\n",
    "\n",
    "    def generateBlurAttribute(self, showSummary=False):\n",
    "        #blurdf = pd.DataFrame(columns=[\"Vollath\", \"Laplacian\", \"Entropy\", \"blurLaplacian\"])\n",
    "        def Vollath(img):\n",
    "            '''\n",
    "            :param img:narray 二维灰度图像\n",
    "            :return: float 图像越清晰越大\n",
    "            '''\n",
    "            shape = np.shape(img)\n",
    "            u = np.mean(img)\n",
    "            out = -shape[0]*shape[1]*(u**2)\n",
    "            for x in range(0, shape[0]-1):\n",
    "                for y in range(0, shape[1]):\n",
    "                    out += int(img[x, y])*int(img[x+1, y])\n",
    "            return out/1000\n",
    "\n",
    "        def entropy(img):\n",
    "            '''\n",
    "            :param img:narray 二维灰度图像\n",
    "            :return: float 图像越清晰越大\n",
    "            '''\n",
    "            out = 0\n",
    "            count = np.shape(img)[0]*np.shape(img)[1]\n",
    "            p = np.bincount(np.array(img).flatten())\n",
    "            for i in range(0, len(p)):\n",
    "                if p[i] != 0:\n",
    "                    out -= p[i]*math.log(p[i]/count)/count\n",
    "            return out\n",
    "\n",
    "        def safe_int(a): return int(a)-1 if int(a)-1 > 0 else int(a)+1\n",
    "        if not self.status[\"merged\"]:\n",
    "            print(\"文件未合并。调用mergeFiles(replace=False)开始拷贝……\")\n",
    "            self.mergeFiles(replace=False)\n",
    "        outPath = \"%sv%s\" % (self.name, self.version.replace(\".\", \"-\"))\n",
    "        imageName_ = \"\"\n",
    "        image = []\n",
    "        blurs = []\n",
    "        trueNum = 0\n",
    "        falseNum = 0\n",
    "        if os.path.exists(\"t\"):\n",
    "            shutil.rmtree(\"t\")\n",
    "        os.mkdir(\"t\")\n",
    "        for annotation in self.annotations:\n",
    "            imageName = self.images[annotation[\"image_id\"]-1][\"file_name\"]\n",
    "            if not imageName_ == imageName:  # 减少IO次数\n",
    "                image = cv2.imread(os.path.join(outPath, imageName))\n",
    "            imageName_ = imageName\n",
    "            [x, y, w, h] = list(map(safe_int, annotation[\"bbox\"]))\n",
    "            imageRoI = cv2.cvtColor(image[y:y+h, x:x+w], cv2.COLOR_BGR2GRAY)\n",
    "            laplacian = cv2.Laplacian(imageRoI, cv2.CV_64F)\n",
    "            area = imageRoI.shape[0] * imageRoI.shape[1]\n",
    "            blurImageRoI = cv2.blur(imageRoI, (3, 3))\n",
    "            bblurLaplacian = cv2.Laplacian(blurImageRoI, cv2.CV_64F).var()\n",
    "#             blurVollath = Vollath(imageRoI)/area\n",
    "            blurLaplacian = cv2.Laplacian(imageRoI, cv2.CV_64F).var()\n",
    "#             blurEntropy = entropy(imageRoI)\n",
    "            #blurdf = blurdf.append(pd.DataFrame([[blurVollath, blurLaplacian, blurEntropy, bblurLaplacian]], columns=[\"Vollath\", \"Laplacian\", \"Entropy\", \"blurLaplacian\"]), ignore_index=True)\n",
    "            blurImageRoI = cv2.resize(blurImageRoI, (w, h))\n",
    "            if blurLaplacian/bblurLaplacian < 4:\n",
    "                annotation[\"attributes\"][\"blur\"] = True\n",
    "                trueNum += 1\n",
    "            else:\n",
    "                annotation[\"attributes\"][\"blur\"] = False\n",
    "                falseNum += 1\n",
    "#             imageOut = np.zeros((5*h,5*w), dtype=\"uint8\")+255\n",
    "#             imageOut[0:h, 0:w] = imageRoI\n",
    "#             imageOut[0:h, w+1:2*w+1] = blurImageRoI\n",
    "#             imageOut = cv2.putText(cv2.cvtColor(imageOut, cv2.COLOR_GRAY2BGR),str(blurLaplacian) , (15, h+25), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "#             imageOut = cv2.putText(imageOut,str(bblurLaplacian) , (15, h+50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "#             imageOut = cv2.putText(imageOut,str(blurLaplacian/bblurLaplacian) , (15, h+75), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "#             if blurLaplacian/bblurLaplacian < 4:\n",
    "#                 cv2.imwrite(\"t/%s.jpg\" % (annotation[\"id\"]), imageOut)\n",
    "        t = PrettyTable([\"blur\", \"True\", \"False\"])\n",
    "        t.add_row([\"\", trueNum, falseNum])\n",
    "        self.attrTables.append(t)\n",
    "        # if showSummary:\n",
    "        #     plt.scatter(blurdf[\"Laplacian\"] /\n",
    "        #                 blurdf[\"blurLaplacian\"], blurdf[\"Laplacian\"])\n",
    "\n",
    "    def generateSizeAttribute(self):\n",
    "        # 实例分割转旋转框by wkl\n",
    "        def instance2obb(img_size, boundary):\n",
    "            '''\n",
    "            Input:\n",
    "                img_size: image size in format (weight, height)\n",
    "                boundary: point sets of instance boundary in format (2*n_points, 1) as list; \n",
    "                          the same as COCO_JSON[\"annotations\"][\"segmentation\"]\n",
    "\n",
    "                Note that only input ONE boundary in one time.\n",
    "\n",
    "            Output:\n",
    "                vertexes: point sets of oriented bounding box in format (2*4, 1) as list; \n",
    "                          the same as COCO_JSON[\"annotations\"][\"segmentation\"]\n",
    "                long_edge: longer edge of obb\n",
    "                short_edge: shorter edge of obb\n",
    "                beyond_flag: if true, obb is out of the border of image\n",
    "\n",
    "            Usage: \n",
    "                vertexes, long_edge, short_edge, beyond_flag = instance2obb(img_size, boundary)\n",
    "                vertexes, long_edge, short_edge, beyond_flag = instance2obb((weight, height), boundary)\n",
    "            '''\n",
    "\n",
    "            max_x, max_y = img_size    # max_x = weight; max_y = height\n",
    "\n",
    "            boundary = np.reshape(boundary, [-1, 2]).astype(np.float32)\n",
    "            obb = cv2.minAreaRect(boundary)\n",
    "            long_edge, short_edge = max(obb[1]), min(obb[1])\n",
    "            vertexes = cv2.boxPoints(obb)\n",
    "\n",
    "            beyond_flag = False\n",
    "            for vertex_x, vertex_y in vertexes:    # Note: x->w; y->h\n",
    "                if (vertex_x < 0) or (vertex_x > max_x) or (vertex_y < 0) or (vertex_y > max_y):\n",
    "                    beyond_flag = True\n",
    "                    break\n",
    "\n",
    "            vertexes = vertexes.astype(np.float64).round(2).flatten().tolist()\n",
    "\n",
    "            return vertexes, long_edge, short_edge, beyond_flag\n",
    "\n",
    "        trueNum = 0\n",
    "        falseNum = 0\n",
    "        for annotation in self.annotations:\n",
    "            imageName = self.images[annotation[\"image_id\"]-1][\"file_name\"]\n",
    "            imageWidth = self.images[annotation[\"image_id\"]-1][\"width\"]\n",
    "            imageHeight = self.images[annotation[\"image_id\"]-1][\"height\"]\n",
    "            v, l, s, b = instance2obb(\n",
    "                (imageWidth, imageHeight), annotation[\"segmentation\"])\n",
    "            if l <= 24:\n",
    "                annotation[\"attributes\"][\"small_size\"] = True\n",
    "                trueNum += 1\n",
    "                continue\n",
    "            annotation[\"attributes\"][\"small_size\"] = False\n",
    "            annotation[\"attributes\"][\"obb_beyond_boundary\"] = b\n",
    "            falseNum += 1\n",
    "        t = PrettyTable([\"size_small\", \"True\", \"False\"])\n",
    "        t.add_row([\"\", trueNum, falseNum])\n",
    "        self.attrTables.append(t)\n",
    "\n",
    "    def generateOvercrowdedAttribute(self, distThreshProportion=0.25):\n",
    "        annotId = 0\n",
    "        trueNum = 0\n",
    "        falseNum = 0\n",
    "\n",
    "        for annotation in self.annotations:\n",
    "            upAnnotId = annotation[\"id\"]-2\n",
    "            downAnnotId = annotation[\"id\"]\n",
    "            bboxes = []\n",
    "            while (upAnnotId >= 0) and (self.annotations[upAnnotId][\"image_id\"] == annotation[\"image_id\"]):\n",
    "                bboxes.append(self.annotations[upAnnotId][\"bbox\"])\n",
    "                upAnnotId -= 1\n",
    "            while (downAnnotId < len(self.annotations)) and (self.annotations[downAnnotId][\"image_id\"] == annotation[\"image_id\"]):\n",
    "                bboxes.append(self.annotations[downAnnotId][\"bbox\"])\n",
    "                downAnnotId += 1\n",
    "            bboxCenters = [[x+w/2, y+h/2] for [x, y, w, h] in bboxes]\n",
    "           # print(bboxCenters)\n",
    "            [x, y, w, h] = annotation[\"bbox\"]\n",
    "            currCenter = [x+w/2, y+h/2]\n",
    "            width = self.images[annotation[\"image_id\"]-1][\"width\"]\n",
    "            height = self.images[annotation[\"image_id\"]-1][\"height\"]\n",
    "            distThresh = distThreshProportion * \\\n",
    "                (width if width < height else height)\n",
    "            isOverCrowded = False\n",
    "            for bboxCenter in bboxCenters:\n",
    "                if annotation.dist(currCenter, bboxCenter) <= distThresh:\n",
    "                    isOverCrowded = True\n",
    "                    break\n",
    "            annotation[\"attributes\"][\"over_crowded\"] = isOverCrowded\n",
    "            if isOverCrowded:\n",
    "                trueNum += 1\n",
    "            else:\n",
    "                falseNum += 1\n",
    "        t = PrettyTable([\"over_crowded\", \"True\", \"False\"])\n",
    "        t.add_row([\"\", trueNum, falseNum])\n",
    "        self.attrTables.append(t)\n",
    "\n",
    "    def cutoutAugmentation(self):\n",
    "        if len(self.annotations) == 0 or len(self.dirList) == 0:\n",
    "            print(\"请先读取一个训练集的标注。中断Cutout增强。\")\n",
    "            return\n",
    "        if len(self.dirList) > 1:\n",
    "            print(\"仅支持单个标注文件的扩充。中断Cutout增强。\")\n",
    "            return\n",
    "        PTSRATIO = 0.25\n",
    "        basePath = self.dirList[0]\n",
    "        targetPath = self.dirList[0] + \"_cutoutAugmented\"\n",
    "\n",
    "        class imageList(list):\n",
    "            def __init__(self, other=[]):\n",
    "                list.__init__([])\n",
    "                self.extend(other)\n",
    "\n",
    "            def getFileName(self, Id):\n",
    "                return self[Id-1][\"file_name\"]\n",
    "\n",
    "            def getImageShape(self, Id):\n",
    "                return [self[Id-1][\"width\"], self[Id-1][\"height\"]]\n",
    "\n",
    "        def safe_int(a): return int(a)-1 if int(a)-1 > 0 else int(a)+1\n",
    "\n",
    "        # 此函数的主代码从preprocess.ipynb迁移而来\n",
    "        if os.path.exists(targetPath):\n",
    "            shutil.rmtree(targetPath)\n",
    "        os.mkdir(targetPath)\n",
    "        ALL = {}\n",
    "        imageFileList = imageList(self.images)\n",
    "        for annotation in self.annotations:\n",
    "            imageFile = imageFileList.getFileName(annotation[\"image_id\"])\n",
    "            [imageWidth, imageHeight] = imageFileList.getImageShape(\n",
    "                annotation[\"image_id\"])\n",
    "            imagePath1 = os.path.join(basePath, imageFile)\n",
    "            imagePath2 = os.path.join(targetPath, imageFile)\n",
    "            image = []\n",
    "            if not os.path.exists(imagePath2):\n",
    "                image = cv2.imread(imagePath1)\n",
    "            else:\n",
    "                image = cv2.imread(imagePath2)\n",
    "            [b, g, r] = cv2.split(image)\n",
    "            imageAvrColor = (int(b.mean()), int(g.mean()), int(r.mean()))\n",
    "            it = iter(annotation[\"segmentation\"][0])\n",
    "            seg = []\n",
    "            while True:\n",
    "                try:\n",
    "                    x = next(it)\n",
    "                    y = next(it)\n",
    "                except StopIteration:\n",
    "                    seg.append(x)\n",
    "                    break\n",
    "                seg.append([safe_int(x), safe_int(y)])\n",
    "            seg = annotation.interplSeg(seg)\n",
    "            segSelStart = random.randint(0, int(len(seg)*(1-PTSRATIO))-1)\n",
    "            segSelEnd = segSelStart + int(len(seg)*PTSRATIO)-1\n",
    "            segSel = seg[segSelStart:segSelEnd]\n",
    "            xMax, yMax, xMin, yMin = [1, 1, imageWidth-1, imageHeight-1]\n",
    "            for [x_, y_] in segSel:\n",
    "                xMax = x_ if x > xMax else xMax\n",
    "                yMax = y_ if y > yMax else yMax\n",
    "                xMin = x_ if x <= xMin else xMin\n",
    "                yMin = y_ if y <= yMin else yMin\n",
    "            startPoint = (int(xMin), int(yMin))\n",
    "            endPoint = (int(xMax), int(yMax))\n",
    "            # TODO: 改变标注文件\n",
    "            thickness = -1\n",
    "            image = cv2.rectangle(\n",
    "                img=image, pt1=startPoint, pt2=endPoint, color=imageAvrColor, thickness=thickness)\n",
    "            cv2.imwrite(imagePath2, image)\n",
    "            print(imagePath2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用默认配置创建新的总标注对象newDataSet v2.0。\n",
      "正在检查标注的标签是否完整……\n",
      "使用\"N/A\"填充所有缺失标签。\n"
     ]
    }
   ],
   "source": [
    "a = annotation(name = \"newDataSet\", version = \"2.0\")\n",
    "a.addSubset(annotPath = \"newDataSet_v2-0.json\", imagePath = \"newDataSetv2-0\")\n",
    "a.generateAttributes()\n",
    "#a.generateOvercrowdedAttribute()\n",
    "a.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+----------+----------+\n",
      "|        源文件        | 图片数量 | 标注数量 |\n",
      "+----------------------+----------+----------+\n",
      "| newDataSet_v2-0.json |   1541   |   2491   |\n",
      "+----------------------+----------+----------+\n",
      "+------+------+-------+\n",
      "| blur | True | False |\n",
      "+------+------+-------+\n",
      "|      | 144  |  2347 |\n",
      "+------+------+-------+\n",
      "+------------+------+-------+\n",
      "| size_small | True | False |\n",
      "+------------+------+-------+\n",
      "|            |  15  |  2476 |\n",
      "+------------+------+-------+\n",
      "+--------------+------+-------+\n",
      "| over_crowded | True | False |\n",
      "+--------------+------+-------+\n",
      "|              | 806  |  1685 |\n",
      "+--------------+------+-------+\n"
     ]
    }
   ],
   "source": [
    "a.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = annotation(name = \"newDataSet\", version = \"2.0\")\n",
    "a.addBatch(fileName = \"新标注数据集v2.txt\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vollath</th>\n",
       "      <th>Laplacian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Vollath Laplacian\n",
       "0       1         2\n",
       "1       3         4\n",
       "2       5         6"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blurdf = pd.DataFrame(columns=[\"Vollath\", \"Laplacian\"])\n",
    "blurdf = blurdf.append(pd.DataFrame([[1, 2]], columns=[\"Vollath\", \"Laplacian\"]), ignore_index=True)\n",
    "blurdf = blurdf.append(pd.DataFrame([[3, 4]], columns=[\"Vollath\", \"Laplacian\"]), ignore_index=True)\n",
    "blurdf = blurdf.append(pd.DataFrame([[5, 6]], columns=[\"Vollath\", \"Laplacian\"]), ignore_index=True)\n",
    "blurdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmlab",
   "language": "python",
   "name": "mmlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
